{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yuan1007/ml_hw1/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "cA3dLD_EDpvL",
        "colab_type": "code",
        "outputId": "8d302f7e-3d15-4386-d8f7-cc7eb75ceb99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xWBRECKDEbvs",
        "colab_type": "code",
        "outputId": "5ee843c3-e46f-477f-fa91-9b1d13e6e94e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir('/content/drive/My Drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['線性代數考題.pdf',\n",
              " 'Algorithm_final.pdf',\n",
              " 'tcm.rar',\n",
              " 'tcm.zip',\n",
              " '607410104_c0e61e (2).docx',\n",
              " 'cert_S107021680.pdf',\n",
              " 'CSS.docx',\n",
              " 'invalid.png',\n",
              " '2018_12_27_編譯器下半.mp3',\n",
              " '2018_12_27_編譯器上半.mp3',\n",
              " 'HW2答案 (1).pdf',\n",
              " 'FinalExam_2017.pdf',\n",
              " '.ssh.rar',\n",
              " 'seg_train',\n",
              " 'intel-image-classification',\n",
              " 'colab',\n",
              " '47.jpg',\n",
              " 'Untitled0.ipynb',\n",
              " 'Colab Notebooks']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "7fqaQmygEyIf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "\n",
        "class VGG16(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(VGG16, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            # input shape: (batch_size, 3, 224, 224) and\n",
        "            # downsampled by a factor of 2^5 = 32 (5 times maxpooling)\n",
        "            # So features' shape is (batch_size, 7, 7, 512)\n",
        "            nn.Linear(in_features=7 * 7 * 512, out_features=4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(in_features=4096, out_features=4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(in_features=4096, out_features=num_classes)\n",
        "        )\n",
        "\n",
        "        # initialize parameters\n",
        "        for module in self.modules():\n",
        "            if isinstance(module, nn.Conv2d):\n",
        "                n = module.kernel_size[0] * module.kernel_size[1] * module.out_channels\n",
        "                module.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                module.bias.data.zero_()\n",
        "            elif isinstance(module, nn.Linear):\n",
        "                module.weight.data.normal_(0, 0.01)\n",
        "                module.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9rtGo4M5EyUw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class IMAGE_Dataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = Path(root_dir)\n",
        "        self.x = []\n",
        "        self.y = []\n",
        "        self.transform = transform\n",
        "        self.num_classes = 0\n",
        "        #print(self.root_dir.name)\n",
        "        for i, _dir in enumerate(self.root_dir.glob('*')):\n",
        "            for file in _dir.glob('*'):\n",
        "                self.x.append(file)\n",
        "                self.y.append(i)\n",
        "\n",
        "            self.num_classes += 1\n",
        "            #print(self.num_classes)\n",
        "        #print(self.num_classes)\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = Image.open(self.x[index]).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, self.y[index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qs-PE2lbEycS",
        "colab_type": "code",
        "outputId": "4445834f-256b-4c4f-c00b-63393d7835dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from pathlib import Path\n",
        "import copy\n",
        "import time\n",
        "\n",
        "# REPRODUCIBILITY\n",
        "torch.manual_seed(1)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# CUDA_DEVICES = 1\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "DATASET_ROOT = '/content/drive/My Drive/intel-image-classification/seg_train'\n",
        "\n",
        "\n",
        "def train():\n",
        "\tdata_transform = transforms.Compose([\n",
        "\t\ttransforms.Resize((224, 224)),\n",
        "\t\ttransforms.ToTensor(),\n",
        "\t\ttransforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\t])\n",
        "\t# print(DATASET_ROOT)\n",
        "\ttrain_set = IMAGE_Dataset(Path(DATASET_ROOT), data_transform)\n",
        "\tdata_loader = DataLoader(\n",
        "\t    dataset=train_set, batch_size=32, shuffle=True, num_workers=3)\n",
        "\t# print(train_set.num_classes)\n",
        "\tmodel = VGG16(num_classes=train_set.num_classes)\n",
        "\t# model = model.cuda(CUDA_DEVICES)\n",
        "\tmodel.to(device)\n",
        "\tmodel.train()\n",
        "\n",
        "\tbest_model_params = copy.deepcopy(model.state_dict())\n",
        "\tbest_acc = 0.0\n",
        "\tnum_epochs = 10\n",
        "\tcriterion = nn.CrossEntropyLoss()\n",
        "\toptimizer = torch.optim.SGD(params=model.parameters(), lr=0.05, momentum=0.9)\n",
        "\n",
        "\tfor epoch in range(num_epochs):\n",
        "\t\tprint(f'Epoch: {epoch + 1}/{num_epochs}')\n",
        "\t\tprint('-' * len(f'Epoch: {epoch + 1}/{num_epochs}'))\n",
        "\n",
        "\t\ttraining_loss = 0.0\n",
        "\t\ttraining_corrects = 0\n",
        "\t\tsince = time.time()        \n",
        "\t\tfor i, (inputs, labels) in enumerate(data_loader):\n",
        "\t\t\tinputs = inputs.to(device)\n",
        "\t\t\tlabels = labels.to(device)\n",
        "\n",
        "\t\t\toptimizer.zero_grad()\n",
        "\n",
        "\t\t\toutputs=model(inputs)\n",
        "\t\t\t_, preds=torch.max(outputs.data, 1)\n",
        "\t\t\tloss=criterion(outputs, labels)\n",
        "\n",
        "\t\t\tloss.backward()\n",
        "\t\t\toptimizer.step()\n",
        "\n",
        "\t\t\ttraining_loss += loss.item() * inputs.size(0)\n",
        "\t\t\t# revise loss.data[0]-->loss.item()\n",
        "\t\t\ttraining_corrects += torch.sum(preds == labels.data)\n",
        "\t\t\t# print(f'training_corrects: {training_corrects}')\n",
        "\t\t\tif(not(i%10)):\n",
        "\t\t\t\tprint(f'iteration done :{i}')\n",
        "\t\ttime_elapsed = time.time() - since\n",
        "\t\tprint(f'time_elapsed:{time_elapsed:.4f}')\n",
        "\t\ttraining_loss=training_loss / len(train_set)\n",
        "\t\ttraining_acc=training_corrects.double() / len(train_set)\n",
        "\t\t# print(training_acc.type())\n",
        "\t\t# print(f'training_corrects: {training_corrects}\\tlen(train_set):{len(train_set)}\\n')\n",
        "\t\tprint(f'Training loss: {training_loss:.4f}\\taccuracy: {training_acc:.4f}\\n')\n",
        "\n",
        "\t\tif training_acc > best_acc:\n",
        "\t\t\tbest_acc=training_acc\n",
        "\t\t\tbest_model_params=copy.deepcopy(model.state_dict())\n",
        "\t\n",
        "\ttime_elapsed = time.time() - since\n",
        "\tprint(f'time_elapsed:{time_elapsed:.4f}')\n",
        "\n",
        "\tmodel.load_state_dict(best_model_params)\n",
        "\ttorch.save(model, f'model-{best_acc:.02f}-best_train_acc.pth')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\ttrain()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/10\n",
            "-----------\n",
            "iteration done :0\n",
            "iteration done :10\n",
            "iteration done :20\n",
            "iteration done :30\n",
            "iteration done :40\n",
            "iteration done :50\n",
            "iteration done :60\n",
            "iteration done :70\n",
            "iteration done :80\n",
            "iteration done :90\n",
            "iteration done :100\n",
            "iteration done :110\n",
            "iteration done :120\n",
            "iteration done :130\n",
            "iteration done :140\n",
            "iteration done :150\n",
            "iteration done :160\n",
            "iteration done :170\n",
            "iteration done :180\n",
            "iteration done :190\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4u1G163V8oZ-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}